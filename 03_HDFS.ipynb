{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFS\n",
    "\n",
    "HDFS is het distributed file system van Hadoop dat de basis vormt voor een breed gamma van applicaties, waaronder MapReduce.\n",
    "Dit framework maakt het mogelijk om niet-gespecialiseerde hardware te gebruiken om eenvoudig datacenters op te zetten of rekenclusters te beheren.\n",
    "HDFS bereikt dit doel op een aantal manieren:\n",
    "* Ten eerste wordt een file opgedeeld in verschillende blokken. Deze worden verdeeld over verschillende computers zodat code meerdere delen van het bestand kan gebruiken in parallel om zo de benodigde rekenkracht te verdelen over meerdere toestellen.\n",
    "* Daarnaast worden de blokken ook gedupliceerd om zo fout-toleranter te zijn in het geval van een crash (hardware of software), stroomstoring, netwerkonderbreking.\n",
    "\n",
    "Om dit te bereiken gebruikt Hadoop een Master-Slave architectuur dat bestaat uit een enkele namenode (master) en meerdere datanodes (slaves).\n",
    "De namenode houdt bij hoeveel datanodes er actief zijn, welke blokken ze hebben en welke blokken bij welke file horen.\n",
    "Indien er een datanode crasht gaat deze server dit detecteren en dit oplossen door de nodige blokken te kopieren van een andere datanode zodat er steeds voldoende kopies in het systeem aanwezig zijn.\n",
    "Bij elke actie die uitgevoerd moet worden in het HDFS moet er steeds gevraagd worden aan de namenode welke blokken op welke datanodes we nodig hebben voor de gewenste file uit te lezen of code voor uit te voeren.\n",
    "Het is dus duidelijk dat deze namenode een single-point-of-failure is wat ideaal is voor de availability van de cluster.\n",
    "Dit kan opgelost worden door HDFS te runnen in een high-availability mode wat ervoor zorgt dat er steeds een backup aanwezig is voor de namenode die zeer snel de werking kan overnemen.\n",
    "Deze structuur maakt het eenvoudig om aan horizontal scaling te doen door extra servers toe te voegen zonder dat er downtime is voor de hele cluster.\n",
    "\n",
    "Dit resulteer in de volgende kenmerken van HDFS:\n",
    "* High Throughput\n",
    "* Scalability\n",
    "* High Availability\n",
    "* Data Reliability\n",
    "* Fault Tolerance\n",
    "\n",
    "## Starten en stoppen van de cluster\n",
    "\n",
    "De cluster kan gestart worden door de volgende commando's uit te voeren in de commandline:\n",
    "* start-dfs.sh\n",
    "* start-yarn.sh\n",
    "\n",
    "Eenmaal dat de cluster gestart is kunnen de lopende java applicaties gecontroleerd worden door middel van het commando jps.\n",
    "Dit kan ook uitgevoerd worden vanuit deze jupyter notebook door onderstaande code-cell uit te voeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!start-dfs.sh\n",
    "!start-yarn.sh\n",
    "!jps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook heeft de namenode een website waar naartoe kan gegaan worden om meer informatie over de cluster te bekijken. De standaardurl is [http://localhost:9870](http://localhost:9870).\n",
    "\n",
    "Om de cluster terug te stoppen moeten in de terminal of de notebook de volgende commando's uitgevoerd worden.\n",
    "* stop-dfs.sh\n",
    "* stop-yarn.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!stop-yarn.sh\n",
    "#!stop-dfs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Communiceren met het HDFS\n",
    "\n",
    "Er zijn verschillende manieren om dit distributed bestandssysteem te gebruiken.\n",
    "Ten eerste kan je gebruik maken van een command line interface (CLI) om bestanden uit te lezen, op te laden, ...\n",
    "Daarnaast zijn er ook wrappers voor verschillende talen die toelaten om rechtstreeks vanuit code te interageren met het HDFS.\n",
    "De voordelen van deze wrappers over een CLI zijn:\n",
    "* Flexibiler om te interageren in applicaties.\n",
    "* Gebruiksvriendelijker en gemakkelijker om te automatiseren.\n",
    "* Eenvoudiger in onderhoud en te debuggen\n",
    "* Volledige functionaliteit van een programmeertaal kan gebruikt worden zoals OO.\n",
    "\n",
    "### Instantiering van een client\n",
    "\n",
    "Veel verschillende talen beschikken over een wrapper om te communiceren met een HDFS.\n",
    "In deze cursus gaan we gebruik maken van [de pydoop](https://crs4.github.io/pydoop/index.html) wrapper.\n",
    "De eerste stap in het gebruik van de wrapper is te bepalen hoe de namenode van het hdfs gevonden kan worden.\n",
    "Dit gebeurt als volgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31040933888"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydoop.hdfs as hdfs\n",
    "# local filesystem\n",
    "localFS = hdfs.hdfs(host='')\n",
    "# initialisation where host (name or ipadress) and port can be defined\n",
    "client = hdfs.hdfs(host='localhost', port=9000)\n",
    "# use hdfs defined in local hadoop configuration files\n",
    "#client = hdfs.hdfs()\n",
    "\n",
    "client.capacity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aanmaken van files en directories\n",
    "\n",
    "Om nu bestanden en folders aan te maken op dit distributed file systeem kunnen onderstaande functies gebruikt worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdfs://localhost:9000/user/bigdata/03_HDFS/03_HDFS/03_HDFS/03_HDFS\n",
      "/home/bigdata/DataspellProjects/Leerstof/03_HDFS/~/DataspellProjects/Leerstof/03_HDFS/~/DataspellProjects/Leerstof/03_HDFS\n"
     ]
    }
   ],
   "source": [
    "#mkdir commando\n",
    "# exists: hdfs dfs -test -d hdfs_path\n",
    "# create: hdfs dfs -mkdir -p /bigdata/03_HDFS\n",
    "if not client.exists('03_HDFS'):\n",
    "    client.create_directory('03_HDFS')\n",
    "# set working directories to reduce overhead of typing paths\n",
    "client.set_working_directory('03_HDFS')\n",
    "print(client.working_directory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hadoop fs -put /path/in/linux /hdfs/path\n",
    "# hadoop fs -get /hdfs/path /path/in/linux\n",
    "localFS.copy(\"davinci_notebooks.txt\", client, \"davinci.txt\")\n",
    "client.copy(\"davinci_notebooks.txt\", client, \"davinci2.txt\")\n",
    "localFS.move(\"ulysses.txt\", client, \"ulysses.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bekijken van het filesysteem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hdfs dfs -ls command\n",
    "client.list_directory(\"\")\n",
    "client.list_directory(\"..\")\n",
    "client.used()\n",
    "client.working_directory()\n",
    "client.default_block_size()\n",
    "\n",
    "# moet gecombineerd worden met head om het uitlezen te stoppen\n",
    "# in tegenstelling tot pydoop waar files kunnen aangepast worden gaat dit niet via CLI\n",
    "# hdfs dfs -cat <hdfs_filename> | head -n 3\n",
    "f = client.open_file(\"ulysses.txt\")\n",
    "for i in range(5):\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aanpassen van het filesysteem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hadoop fs -mv oldname newname\n",
    "client.rename(\"davinci2.txt\", \"davinci3.txt\")\n",
    "# hdfs dfs -rm path\n",
    "# add -r tag for deleting directory\n",
    "client.delete(\"davinci3.txt\")\n",
    "# hdfs dfs –setrep –w 3 /tmp/logs/file.txt\n",
    "client.set_replication(\"davinci.txt\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oefening\n",
    "\n",
    "Schrijf python code dat controleert of een directory bestaat in het hdfs.\n",
    "Indien nee wordt de directory aangemaakt.\n",
    "Indien ja, worden alle files in de directory verwijderd om van een lege directory te starten.\n",
    "Upload daarna een tekst-bestand naar keuze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not client.exists('/user/bigdata/03_HDFS'):\n",
    "    client.create_directory('/user/bigdata/03_HDFS')\n",
    "else:\n",
    "    # do some cleaning in case anything else than input.txt is present\n",
    "    for f in client.list_directory(\".\"):\n",
    "        if not f[\"name\"].endswith(\"input.txt\"):\n",
    "            client.delete(f[\"name\"], True)\n",
    "            \n",
    "localFS.copy(\"davinci_notebooks.txt\", client, \"03_HDFS/davinci.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
